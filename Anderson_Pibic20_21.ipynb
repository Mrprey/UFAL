{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Anderson_Pibic20-21.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Kuw76bXTpeTD",
        "x0B5-Xb8Za2j",
        "vCAb6_lC1v9P",
        "70QYeJvQ3nbt",
        "WhLfygNn4CNE",
        "rrB_97x34HED"
      ],
      "mount_file_id": "1pkDksvcn9x_vkcdjVSGB81PPY2VourKj",
      "authorship_tag": "ABX9TyO6B9/AdIS5u6guMSAdFKvO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mrprey/UFAL/blob/master/Anderson_Pibic20_21.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8WwLdYnxttH"
      },
      "source": [
        "##Bibliotecas\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbfYIVowxwx-"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from numba import vectorize, float64, njit, jit, int32\n",
        "from sklearn.manifold import MDS,TSNE\n",
        "import time\n",
        "import sys\n",
        "from sklearn.utils.extmath import randomized_svd\n",
        "from scipy.spatial.distance import cdist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XnBVO5Ke72B"
      },
      "source": [
        "# LAMP\n",
        "\n",
        "Local Affine Multidimensional Projection\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "[Repositorio do autor](https://github.com/lgnonato/LAMP)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okwVJaEsfCuA"
      },
      "source": [
        "# Author: Luis Gustavo Nonato  -- <gnonato@icmc.usp.br>\n",
        "# License: BSD 3 - Clause License 2018\n",
        "\n",
        "# This is an implementation of the technique described in:\n",
        "# http://www.lcad.icmc.usp.br/~nonato/pubs/lamp.pdf\n",
        "epsilon = 1e-7\n",
        "\n",
        "class Lamp():\n",
        "    def __init__(self, Xdata = None, control_points = None, weights = None, label=False, scale=True, dim = 2):\n",
        "        '''\n",
        "          Xdata: N_by_K matrix where N is the number of instances and K is the dimension\n",
        "          control_points: M_by_(dim + 1) matrix with the coordinates of the control points\n",
        "                        in the image space. The last column contains the ids of the control\n",
        "                        points in the Xdata matrix\n",
        "          weights: N_by_M matrix where weights[i,j] is the weight between Xdata[i] and\n",
        "                   control_point[j]. If weights=None the inverse of the Euclidean distance is used as weight\n",
        "          label: when True assumes the last column of Xdata as labels\n",
        "          scale: apply a transformation in the control points before accomplish the mapping.\n",
        "                 Produce better projections when the original and control points coordiantes has very different scales.\n",
        "          dim: dimension of the image space\n",
        "        '''\n",
        "        self.data = None\n",
        "        self.mapped = None\n",
        "        self.control_points = None\n",
        "        self.control_points_data = None\n",
        "        self.weights = weights\n",
        "        self.dim = dim\n",
        "        self.labels = None\n",
        "        self.label = label\n",
        "        self.scale = scale\n",
        "        self.data_center = None\n",
        "        self.control_points_center = None\n",
        "        self.U = None\n",
        "        self.S = None\n",
        "        self.V = None\n",
        "\n",
        "        if Xdata is not None:\n",
        "            try:\n",
        "                if type(Xdata) is not np.ndarray:\n",
        "                    raise TypeError()\n",
        "\n",
        "                if label is False:\n",
        "                    self.center(Xdata,o_c_s='o')\n",
        "                else:\n",
        "                    self.center(Xdata[:,:-1],o_c_s='o')\n",
        "                    self.labels = Xdata[:,-1].astype(int)\n",
        "\n",
        "            except (AttributeError, TypeError):\n",
        "                print('----- LAMP Error -----')\n",
        "                print('Xdata must be a Numpy Array')\n",
        "                sys.exit()\n",
        "\n",
        "        if control_points is not None:\n",
        "            try:\n",
        "                if type(control_points) is not np.ndarray:\n",
        "                    raise TypeError()\n",
        "\n",
        "            except (AttributeError, TypeError):\n",
        "                print('----- LAMP Error -----')\n",
        "                print('control_points must be a Numpy Array')\n",
        "                sys.exit()\n",
        "\n",
        "            self.center(control_points,o_c_s='c')\n",
        "\n",
        "\n",
        "#########\n",
        "    def fit(self,Xdata=None):\n",
        "        ''' decide if the mapping should be trigger with or without control points'''\n",
        "        if Xdata is not None:\n",
        "            try:\n",
        "                if type(Xdata) is not np.ndarray:\n",
        "                    raise TypeError()\n",
        "\n",
        "                if self.data is not None:\n",
        "                    if self.label is True:\n",
        "                        self.center(Xdata[:,:-1],o_c_s='s')\n",
        "                        self.labels = Xdata[:,-1].astype(int)\n",
        "                    else:\n",
        "                        self.center(Xdata,o_c_s='s')\n",
        "                else:\n",
        "                    if self.label is True:\n",
        "                        self.center(Xdata[:,:-1],o_c_s='o')\n",
        "                        self.labels = Xdata[:,-1].astype(int)\n",
        "                    else:\n",
        "                        self.center(Xdata,o_c_s='o')\n",
        "\n",
        "            except (AttributeError, TypeError):\n",
        "                print('----- LAMP Error -----')\n",
        "                print('Type Error: Xdata must be a Numpy Array')\n",
        "                sys.exit()\n",
        "        else:\n",
        "            try:\n",
        "                if self.data is None:\n",
        "                    raise ValueError()\n",
        "\n",
        "            except ValueError:\n",
        "                print('----- LAMP Error -----')\n",
        "                print('No data to map')\n",
        "                sys.exit()\n",
        "\n",
        "        if self.control_points is not None:\n",
        "            if (self.scale is True) and (self.S is None):\n",
        "                self.scale_control_points()\n",
        "\n",
        "            self.map()\n",
        "\n",
        "            if self.scale is True:\n",
        "                self.unscale()\n",
        "\n",
        "            mapped = self.mapped + self.control_points_center\n",
        "            if self.label is True:\n",
        "                mapped = np.hstack((mapped,self.labels.reshape(self.labels.shape[0],1)))\n",
        "        else:\n",
        "            self.control_points_free_mapping()  # To be implemented soon\n",
        "            mapped = self.mapped\n",
        "\n",
        "\n",
        "        return(mapped)\n",
        "\n",
        "#########\n",
        "    def map(self):\n",
        "        ''' mapping using control points '''\n",
        "        n,k = self.data.shape\n",
        "        m = self.control_points.shape[0]\n",
        "        self.mapped = np.zeros((n,self.dim))\n",
        "        ctp_mapped = self.control_points[:,:-1]\n",
        "        ctp_data = self.control_points_data\n",
        "\n",
        "        if self.weights is None:\n",
        "            self.weights = cdist(self.data,ctp_data,p=2.)\n",
        "            self.weights = 1.0/(self.weights+epsilon)\n",
        "\n",
        "        for i in range(n):\n",
        "            alpha = np.sum(self.weights[i])\n",
        "            x_tilde = np.dot(ctp_data.T,self.weights[i].T)/alpha\n",
        "            y_tilde = np.dot(ctp_mapped.T,self.weights[i].T)/alpha\n",
        "            x_hat = ctp_data - x_tilde\n",
        "            y_hat = ctp_mapped - y_tilde\n",
        "            D = np.diag(np.sqrt(self.weights[i]))\n",
        "            A = np.dot(D,x_hat)\n",
        "            B = np.dot(D,y_hat)\n",
        "            U,s,V = randomized_svd(np.dot(A.T,B), n_components=2, random_state=None)\n",
        "            M = np.dot(U,V)\n",
        "            self.mapped[i] = np.dot((self.data[i] - x_tilde),M)+y_tilde\n",
        "\n",
        "#########\n",
        "    def center(self,X,o_c_s='o'):\n",
        "        '''o_c_s distriminate between original data (o), control points (c), and streaming data (s)'''\n",
        "        if o_c_s == 'o':\n",
        "            Xmean = np.average(X, axis=0)\n",
        "            self.data_center = Xmean\n",
        "            self.data = np.subtract(X,Xmean)\n",
        "\n",
        "        if o_c_s == 'c':\n",
        "            ctp_ids = X[:,-1].astype(int)\n",
        "            self.control_points_data = self.data[ctp_ids]\n",
        "            Xmean = np.average(X[:,0:2], axis=0)\n",
        "            self.control_points_center = Xmean\n",
        "            centered = np.subtract(X[:,0:2],Xmean)\n",
        "            self.control_points = np.hstack((centered,X[:,-1].reshape(-1,1)))\n",
        "\n",
        "        if o_c_s == 's':\n",
        "            self.data = np.subtract(X,self.data_center)\n",
        "\n",
        "#########\n",
        "    def scale_control_points(self):\n",
        "        ctp_ids = self.control_points[:,-1].astype(int)\n",
        "        ctp_mapped = self.control_points[:,:-1]\n",
        "        ctp_data = self.data[ctp_ids]\n",
        "        Uo,So,Vo = randomized_svd(ctp_data.T, n_components=2, random_state=None)\n",
        "        Uc,Sc,Vc = randomized_svd(ctp_mapped.T, n_components=2, random_state=None)\n",
        "        DSo = np.diag(So)\n",
        "        self.control_points[:,:-1] = np.dot(np.dot(Uc,DSo),Vc).T\n",
        "\n",
        "        self.U = Uc\n",
        "        self.S = np.diag(Sc)\n",
        "        self.So = np.diag(So)\n",
        "        self.V = Vc\n",
        "\n",
        "#########\n",
        "    def unscale(self):\n",
        "        proj = np.dot(self.U.T,self.mapped.T)\n",
        "        Sinv = np.zeros((2,2))\n",
        "        Sinv[0,0] = 1.0/self.So[0,0]\n",
        "        Sinv[1,1] = 1.0/self.So[1,1]\n",
        "        proj_unscaled = np.dot(Sinv,proj)\n",
        "        self.mapped = np.dot(self.U,np.dot(self.S,proj_unscaled)).T\n",
        "\n",
        "#########\n",
        "    def control_points_free_mapping(self):\n",
        "        ''' Mapping without control points '''\n",
        "        def stress(p,pt,d):\n",
        "            cost = 0\n",
        "            for i in range(3):\n",
        "                cost += ((p[0]-pt[i,0])**2+(p[1]-pt[i,1])**2-d[i])**2\n",
        "            return(cost)\n",
        "\n",
        "        max_dist = 1e8\n",
        "        n = self.data.shape[0]\n",
        "        knn = 5\n",
        "        self.mapped = np.zeros((n,self.dim))\n",
        "\n",
        "        D = cdist(self.data,self.data,p=2.)\n",
        "\n",
        "        # finding the 3 first points that give rise to the inicial triangle\n",
        "\n",
        "        ### starting with the farthest 2 points\n",
        "        idx_flat = np.argmax(D)\n",
        "        idx_i = idx_flat//n\n",
        "        idx_j = idx_flat - n*idx_i\n",
        "\n",
        "        ### starting with 2 random\n",
        "        #idx_i = int(np.random.randint(low=0,high=n,size=1))\n",
        "        #idx_j = int(np.random.randint(low=0,high=n,size=1))\n",
        "        #while (idx_j == idx_i):\n",
        "        #    idx_j = int(np.random.randint(low=0,high=n,size=1))\n",
        "\n",
        "        d01 = D[idx_i,idx_j]\n",
        "        d01 += epsilon\n",
        "        D[idx_i,idx_j] = 0\n",
        "        D[idx_j,idx_i] = 0\n",
        "        processed_points = [idx_i,idx_j]\n",
        "\n",
        "        D_processed = D[processed_points]\n",
        "        idx_flat = np.argmax(D_processed)\n",
        "        idx_i = idx_flat//n\n",
        "        idx_j = idx_flat - n*idx_i\n",
        "        d02 = D[processed_points[0],idx_j]**2 + epsilon\n",
        "        d12 = D[processed_points[1],idx_j]**2 + epsilon\n",
        "        D[processed_points,idx_j] = 0\n",
        "        D[idx_j,processed_points] = 0\n",
        "        processed_points.append(idx_j)\n",
        "\n",
        "        # computing the initial triangle\n",
        "        x = (-d12+d02+d01**2)/(2.0*d01)\n",
        "        y = np.sqrt(d02-x**2)\n",
        "        ltemp = [(0,0),(d01,0),(x,y)]\n",
        "        proj_tri = np.asarray(ltemp)\n",
        "        self.mapped[processed_points] = proj_tri[:]\n",
        "\n",
        "\n",
        "        # computing k more initial points\n",
        "        for i in range(3,knn):\n",
        "            D_processed = D[processed_points]\n",
        "            idx_flat = np.argmax(D_processed)\n",
        "            idx_i = idx_flat//n\n",
        "            idx_j = idx_flat - n*idx_i\n",
        "            d = np.asarray([D[processed_points[0],idx_j]**2+epsilon, D[processed_points[1],idx_j]**2+epsilon, D[processed_points[2],idx_j]**2+epsilon])\n",
        "            D[processed_points,idx_j] = 0\n",
        "            D[idx_j,processed_points] = 0\n",
        "            processed_points.append(idx_j)\n",
        "\n",
        "            res = minimize(stress, np.asarray([0,0]),args=(proj_tri,d))\n",
        "            self.mapped[idx_j] = res.x\n",
        "\n",
        "        D = D + max_dist*np.identity(n)\n",
        "        for idx_j in processed_points:\n",
        "            D[processed_points,idx_j] = max_dist\n",
        "            D[idx_j,processed_points] = max_dist\n",
        "\n",
        "        # mapping the data set\n",
        "        weights = np.zeros((knn,))\n",
        "        for i in range(knn,n):\n",
        "            D_processed = D[processed_points]\n",
        "            idx_flat = np.argmin(D_processed)\n",
        "            idx_i = idx_flat//n\n",
        "            idx_j = idx_flat - n*idx_i\n",
        "\n",
        "            neighbors_ids = np.argpartition(D[idx_j,processed_points],knn-1)[:knn]\n",
        "            ctp_ids = [processed_points[j] for j in neighbors_ids]\n",
        "            weights[:] = D[idx_j,ctp_ids]\n",
        "            weights = 1.0/(weights+epsilon)\n",
        "            ctp_data = self.data[ctp_ids]\n",
        "            ctp_mapped = self.mapped[ctp_ids]\n",
        "\n",
        "            alpha = np.sum(weights)\n",
        "            x_tilde = np.dot(ctp_data.T,weights.T)/alpha\n",
        "            y_tilde = np.dot(ctp_mapped.T,weights.T)/alpha\n",
        "            x_hat = ctp_data - x_tilde\n",
        "            y_hat = ctp_mapped - y_tilde\n",
        "            S = np.diag(np.sqrt(weights))\n",
        "            A = np.dot(S,x_hat)\n",
        "            B = np.dot(S,y_hat)\n",
        "            U,s,V = randomized_svd(np.dot(A.T,B), n_components=2, random_state=None)\n",
        "            M = np.dot(U,V)\n",
        "            self.mapped[idx_j] = np.dot((self.data[idx_j] - x_tilde),M)+y_tilde\n",
        "\n",
        "            D[processed_points,idx_j] = max_dist\n",
        "            D[idx_j,processed_points] = max_dist\n",
        "            processed_points.append(idx_j)\n",
        "\n",
        "def LAMPx(df_sample):\n",
        "    sample_size = 7\n",
        "    samples = np.random.randint(0, high=df_sample.shape[0], size=(sample_size,))\n",
        "\n",
        "    # Projetar os pontos de Controle com o MDS\n",
        "\n",
        "    ctp_mds = MDS(n_components=2)\n",
        "    ctp_samples = ctp_mds.fit_transform(df_sample[samples]-np.average(df_sample[samples]))\n",
        "\n",
        "    # Inclui os pontos de controle na ultima coluna\n",
        "    ctp_samples = np.hstack((ctp_samples, samples.reshape(sample_size,1)))\n",
        "\n",
        "    # Executando a LAMP\n",
        "\n",
        "    lamp_proj = Lamp(Xdata = df_sample, control_points=ctp_samples, label=True)\n",
        "    data_sample_proj = lamp_proj.fit()\n",
        "    return data_sample_proj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGCBrcdptmPi"
      },
      "source": [
        "#obtendo os dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNVftBGvyC8t"
      },
      "source": [
        "Data set original"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DvGP85T2N7h"
      },
      "source": [
        "color_histogram = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/dataFiles/ColorHistogram.data',skiprows=4, sep=\";\", index_col=0)\n",
        "mammals = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/dataFiles/mammals-50000.bin-normcols.data',skiprows=4, sep=\";\", index_col=0)\n",
        "fibers = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/dataFiles/fibers.data',skiprows=4, sep=\";\", index_col=0)\n",
        "multifield = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/dataFiles/multifield.0099-normcols.bin-200000.data',skiprows=4, sep=\";\", index_col=0)\n",
        "phy = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/dataFiles/phy.data',skiprows=4, sep=\";\", index_col=0)\n",
        "shuttle = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/dataFiles/shuttle_trn_corr-normcols.data',skiprows=4, sep=\";\", index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51n62OEPyXqU"
      },
      "source": [
        "Data set projetado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozth86z1yapM"
      },
      "source": [
        "proj_color_histogram, proj_mammals, proj_fibers, proj_multifield, proj_phy, proj_shuttle = [], [], [], [], [], []\n",
        "\n",
        "for i in range(10):\n",
        "  proj_color_histogram.append(pd.DataFrame(LAMPx(color_histogram.to_numpy())))\n",
        "  proj_mammals.append(pd.DataFrame(LAMPx(mammals.to_numpy())))\n",
        "  proj_fibers.append(pd.DataFrame(LAMPx(fibers.to_numpy())))\n",
        "  proj_multifield.append(pd.DataFrame(LAMPx(multifield.to_numpy())))\n",
        "  proj_phy.append(pd.DataFrame(LAMPx(phy.to_numpy())))\n",
        "  proj_shuttle.append(pd.DataFrame(LAMPx(shuttle.to_numpy())))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPVxIG5L0FwV"
      },
      "source": [
        "def salvar_arquivo(nome, valor, data_set, tempo):\n",
        "    nome = nome + '.txt'\n",
        "    valor = str(round(valor, 4))\n",
        "    tempo = str(round(tempo, 4))\n",
        "    arquivo = open('/content/drive/MyDrive/Colab Notebooks/Resultados/'+ nome, 'a')\n",
        "    arquivo.write(data_set + ',' + tempo + ',' + valor +'\\n')\n",
        "    arquivo.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRKLVWvS0G8F"
      },
      "source": [
        "##Funções para salvar os arquivos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kuw76bXTpeTD"
      },
      "source": [
        "Metricas de qualidade\n",
        "# Trustworthiness\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_RE7xYH3AOu"
      },
      "source": [
        "A confiabilidade de Mt resulta em  valores entre 0 e 1, onde 1 é o caso ideial. Ela mede a proporção de pontos do espaço N que não estão em conjunto dos vizinhos no 2D.\n",
        "\n",
        "Onde N é igual ao número de dimensões do conjuto de dados, \n",
        "K é um valor arbirtrário dado pelo usuario que será utilizado para o calculo do numero de vizinhos para um ponto, \n",
        "n é o número de amostras(quantidade de dados a serem analisados), e Ui(k) é um conjunto de dados com os vizinhos de um ponto i no 2D mas que não estão entre os K vizinhos do ND(conjunto de dados), r(i, j) é a classificação do ponto no 2D, j é um conjunto ordenado dos vizinhos mais proximos do ponto i, e i é um ponto do conjunto.\n",
        "\n",
        "\n",
        "$Mt = 1 - \\frac{2}{NK(2n - 3K - 1)} \\sum\\limits_{i=1}^{N}\\sum\\limits_{j \\epsilon Ui(K)}(r(i,j) - K)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXP3YyMqS8ou"
      },
      "source": [
        "original \n",
        "\n",
        "Trustworthiness Mt: With values in [0, 1], with 1 being\n",
        "the best, this measures the proportion of points in D that\n",
        "are also close in P(D) [20]. A related metric measures\n",
        "the false neighbors of a projected point [97]. Mt tells how\n",
        "much one can trust that local patterns in a projection,\n",
        "e.g., clusters, represent actual patterns in the data. In the\n",
        "definition (Tab. 5), U\n",
        "(K)\n",
        "i\n",
        "is the set of points that are among\n",
        "the K nearest neighbors of point i in the 2D space but not\n",
        "among the K nearest neighbors of point i in R\n",
        "n; and r(i, j)\n",
        "is the rank of the 2D point j in the ordered set of nearest\n",
        "neighbors of i in 2D. We chose K = 7 for this study, in line\n",
        "with [13], [98];"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0B5-Xb8Za2j"
      },
      "source": [
        "## codigo Rafael"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKv_XsVwZln8"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def trustworthiness_o(D_high, D_low, k=7):\n",
        "\n",
        "    n = D_high.shape[0]\n",
        "    \n",
        "\n",
        "    nn_orig = np.argsort(D_high)\n",
        "    nn_proj = np.argsort(D_low)\n",
        "\n",
        "    \n",
        "    knn_orig = nn_orig[:, :k + 1][:, 1:]\n",
        "    knn_proj = nn_proj[:, :k + 1][:, 1:]\n",
        "\n",
        "    sum_i = 0\n",
        "\n",
        "    for i in range(n):\n",
        "        U = np.setdiff1d(knn_proj[i], knn_orig[i])\n",
        "\n",
        "        sum_j = 0\n",
        "        for j in range(U.shape[0]):\n",
        "            sum_j += np.where(nn_orig[i] == U[j], nn_orig[i], U[j])[0] - k\n",
        "\n",
        "        sum_i += sum_j\n",
        "\n",
        "    return float((1 - (2 / (n * k * (2 * n - 3 * k - 1)) * sum_i)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCAb6_lC1v9P"
      },
      "source": [
        "## Codigo paralelizado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWLsb178iQIH"
      },
      "source": [
        "##@njit\n",
        "def trustworthiness_p(D_high, D_low, k=7):\n",
        "    n = D_high.shape[0]\n",
        "    \n",
        "\n",
        "    nn_orig = np.argsort(D_high)\n",
        "    nn_proj = np.argsort(D_low)\n",
        "\n",
        "    \n",
        "    knn_orig = nn_orig[:, :k + 1][:, 1:]\n",
        "    knn_proj = nn_proj[:, :k + 1][:, 1:]\n",
        "\n",
        "    sum_i = 0\n",
        "\n",
        "    for i in range(n):\n",
        "      U = np.setdiff1d(knn_proj[i], knn_orig[i])\n",
        "      sum_i += second_calc(nn_orig[i], U, k)\n",
        "\n",
        "    return float((1 - (2 / (n * k * (2 * n - 3 * k - 1)) * sum_i)))\n",
        "\n",
        "@njit\n",
        "def second_calc(nn_orig, U, k):\n",
        "    sum_j = 0\n",
        "    for j in range(U.shape[0]):\n",
        "        sum_j += np.where(nn_orig == U[j], nn_orig, U[j])[0] - k\n",
        "\n",
        "    return sum_j"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRRXhT48-mxT"
      },
      "source": [
        "# Continuity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I569ecjy_QHj"
      },
      "source": [
        "A confiabilidade de Mc resulta em valores entre 0 e 1, onde 1 é o caso ideial. Ela mede a proporção de vizinhos de um ponto, onde relaciona a quantidade vizinhos ausentes de um ponto no espaço projetado.\n",
        "\n",
        "Onde N é igual ao número de dimensões do conjuto de dados, K é um valor arbirtrário dado pelo usuario que será utilizado para o calculo do numero de vizinhos para um ponto, n é o número de amostras(quantidade de dados a serem analisados), e Vi(k) é um conjunto de dados com os vizinhos de um ponto i no Rn(espaço original) mas que não estão entre os K vizinhos do 2D, r(i, j) é a classificação do ponto no Rn, j é um conjunto ordenado dos vizinhos mais proximos do ponto i no Rn, e i é um ponto do conjunto.\n",
        "\n",
        "\n",
        "$Cn = 1 - \\frac{2}{NK(2n - 3K - 1)} \\sum\\limits_{i=1}^{N}\\sum\\limits_{j \\epsilon Vi(K)}(r^-(i,j) - K)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEcDQkvZTPNX"
      },
      "source": [
        "original\n",
        "\n",
        "Continuity Mc: With values in [0, 1], with 1 being the\n",
        "best, this measures the proportion of points in P(D) that\n",
        "are also close together in D [20]. It is closely related to\n",
        "the missing neighbors of a projected point [97]. In the\n",
        "definition (Tab. 5), V\n",
        "(K)\n",
        "i\n",
        "is the set of points that are among\n",
        "the K nearest neighbors of point i in R\n",
        "n but not among the\n",
        "K nearest neighbors in 2D; and rˆ(i, j) is the rank of the R\n",
        "n\n",
        "point j in the ordered set of nearest neighbors of i in R\n",
        "n.\n",
        "As for Mt, we chose K = 7.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CDCuWYnjf5E"
      },
      "source": [
        "## codigo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd0aZDezG7kO"
      },
      "source": [
        "###Paralelizado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSuz4nGejiHc"
      },
      "source": [
        "def continuity_p(D_high, D_low, k=7):\n",
        "    \n",
        "    n = D_high.shape[0]\n",
        "\n",
        "    nn_orig = D_high.argsort()\n",
        "    nn_proj = D_low.argsort()\n",
        "\n",
        "    knn_orig = nn_orig[:, :k + 1][:, 1:]\n",
        "    knn_proj = nn_proj[:, :k + 1][:, 1:]\n",
        "\n",
        "    sum_i = 0\n",
        "\n",
        "    for i in range(n):\n",
        "        V = np.setdiff1d(knn_orig[i], knn_proj[i])\n",
        "        sum_i += second_calc(nn_proj[i], V, k)\n",
        "\n",
        "    return float((1 - (2 / (n * k * (2 * n - 3 * k - 1)) * sum_i)))\n",
        "\n",
        "@njit\n",
        "def second_calc(nn_proj, V, k):\n",
        "  sum_j = 0\n",
        "  for j in range(V.shape[0]):\n",
        "      sum_j += np.where(nn_proj == V[j], nn_proj, V[j])[0] - k\n",
        "\n",
        "  return sum_j\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cU7G6TsGG5B2"
      },
      "source": [
        "###Rafael"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qjp_3888NTZi"
      },
      "source": [
        "def continuity(D_high, D_low, k=7):\n",
        "    \n",
        "    n = D_high.shape[0]\n",
        "\n",
        "    nn_orig = D_high.argsort()\n",
        "    nn_proj = D_low.argsort()\n",
        "\n",
        "    knn_orig = nn_orig[:, :k + 1][:, 1:]\n",
        "    knn_proj = nn_proj[:, :k + 1][:, 1:]\n",
        "\n",
        "    sum_i = 0\n",
        "\n",
        "    for i in range(n):\n",
        "        V = np.setdiff1d(knn_orig[i], knn_proj[i])\n",
        "\n",
        "        sum_j = 0\n",
        "        for j in range(V.shape[0]):\n",
        "            sum_j += np.where(nn_proj[i] == V[j], nn_proj[i], V[j])[0] - k\n",
        "        #print(sum_j)\n",
        "        sum_i += sum_j\n",
        "    \n",
        "    return float((1 - (2 / (n * k * (2 * n - 3 * k - 1)) * sum_i)))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70QYeJvQ3nbt"
      },
      "source": [
        "#Stress de kruskal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhLfygNn4CNE"
      },
      "source": [
        "##Sress paralelizado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDeN1viP4FLN"
      },
      "source": [
        "@vectorize([float64(float64, float64), float64(float64, float64), float64(float64, float64), float64(float64, float64)])\n",
        "def top_p(Matriz_Dist, Matriz_proj):\n",
        "    return (Matriz_Dist - Matriz_proj) ** 2\n",
        "\n",
        "\n",
        "@njit(fastmath=True, nogil=True)\n",
        "def somatorio_p(Matriz_o, Matriz_p):\n",
        "    print('calculando stress paralelizado')\n",
        "    '''Matriz_o: matriz do espaço original\n",
        "    Matriz_p: matriz do espaço projetado'''\n",
        "    somab = 0  # somatorio da parte inferior do calculo do stress de kruskal\n",
        "    somat = 0  # somatorio da parte superior do calculo do stress de kruskal\n",
        "    shape = np.shape(Matriz_o)  # vai pegar a quantidade de linha e colunas respectivamente\n",
        "    for i in range(0, shape[0]):\n",
        "        result = calculation_parts_p(Matriz_o, Matriz_p, i, i + 1, shape[0])\n",
        "        somab += result[0]\n",
        "        somat += result[1]\n",
        "\n",
        "    return somat / somab\n",
        "\n",
        "\n",
        "@njit(fastmath=True, nogil=True)\n",
        "def calculation_parts_p(Mo, Mp, stance, init, end):\n",
        "    '''\n",
        "    Mo: matriz do espaço original\n",
        "    Mp: matriz do espaço projetado\n",
        "    stance: equivale o primeiro i do somatorio, onde ele é fixo até terminar o segundo somatorio\n",
        "    init: equivale a o i do segundo somatorio, onde ele inicia i anterior mais 1 para nao repetir calculo\n",
        "    end: o valor final de i que pode ser alcançado\n",
        "    columns: são o número de colunas da matriz original, -2 pq o primeiro e o ultimo valor da linha não entra no calculo\n",
        "    e o columns sem isso teria a quantidade de colunas\n",
        "    '''\n",
        "    somab = 0\n",
        "    somat = 0\n",
        "    for j in range(init, end):  # isto serve para não calcular linhas anteriores já calculdas\n",
        "\n",
        "        # o primeiro parametro da linha não entrar no calculo pq é o indice da matriz e o ultimo era de classificação\n",
        "        distanciaO = (np.sum(top_p(Mo[stance], Mo[j]))) ** 0.5\n",
        "        # o mesmo caso anterior do commit anterior\n",
        "        distanciap = (np.sum(top_p(Mp[stance], Mp[j]))) ** 0.5\n",
        "\n",
        "        somab += distanciaO ** 2  # da formula onde a distancia do espaço projetado na parte inferior é elevado ao\n",
        "        # quadrado\n",
        "        somat += top_p(distanciaO, distanciap)\n",
        "\n",
        "    return somab, somat\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrB_97x34HED"
      },
      "source": [
        "##Stress original"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJMu-gWb4J50"
      },
      "source": [
        "def top(Matriz_Dist, Matriz_proj):\n",
        "    return (Matriz_Dist - Matriz_proj) ** 2\n",
        "\n",
        "def somatorio(Matriz_o, Matriz_p):\n",
        "    #print('calculando stress não paralelizado')\n",
        "    '''Matriz_o: matriz do espaço original\n",
        "    Matriz_p: matriz do espaço projetado'''\n",
        "    somab = 0  # somatorio da parte inferior do calculo do stress de kruskal\n",
        "    somat = 0  # somatorio da parte superior do calculo do stress de kruskal\n",
        "    shape = np.shape(Matriz_o)  # vai pegar a quantidade de linha e colunas respectivamente\n",
        "    for i in range(0, shape[0]):\n",
        "        result = calculation_parts(Matriz_o, Matriz_p, i, i + 1, shape[0], shape[1] - 2)\n",
        "        somab += result[0]\n",
        "        somat += result[1]\n",
        "\n",
        "    return somat / somab\n",
        "\n",
        "\n",
        "def calculation_parts(Mo, Mp, stance, init, end, columns):\n",
        "    '''\n",
        "    Mo: matriz do espaço original\n",
        "    Mp: matriz do espaço projetado\n",
        "    stance: equivale o primeiro i do somatorio, onde ele é fixo até terminar o segundo somatorio\n",
        "    init: equivale a o i do segundo somatorio, onde ele inicia i anterior mais 1 para nao repetir calculo\n",
        "    end: o valor final de i que pode ser alcançado\n",
        "    columns: são o número de colunas da matriz original, -2 pq o primeiro e o ultimo valor da linha não entra no calculo\n",
        "    e o columns sem isso teria a quantidade de colunas\n",
        "    '''\n",
        "    somab = 0\n",
        "    somat = 0\n",
        "    for j in range(init, end):  # isto serve para não calcular linhas anteriores já calculdas\n",
        "\n",
        "        # o primeiro parametro da linha não entrar no calculo pq é o indice da matriz e o ultimo era de classificação\n",
        "        distanciaO = (np.sum(top(Mo[stance][1:columns], Mo[j][1:columns]))) ** 0.5\n",
        "        # o mesmo caso anterior do commit anterior\n",
        "        distanciap = (np.sum(top(Mp[stance][1:3], Mp[j][1:3]))) ** 0.5\n",
        "\n",
        "        somab += distanciaO ** 2  # da formula onde a distancia do espaço projetado na parte inferior é elevado ao\n",
        "        # quadrado\n",
        "        somat += top(distanciaO, distanciap)\n",
        "\n",
        "    return somab, somat\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmvgMUCG3gZd"
      },
      "source": [
        "#Ambiente de Testes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQZyVXAd5sx2"
      },
      "source": [
        "##testes TW"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Y1UvPf650Af"
      },
      "source": [
        "###TW original"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exRqLMUX6oQq"
      },
      "source": [
        "####mammals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rYP07JLull6"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = trustworthiness_o(mammals.to_numpy(),proj_mammals[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('TW original', valor, 'mammals', tempo_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mJQlVdE7agO"
      },
      "source": [
        "####Color Histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxLuucW77kgP"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = trustworthiness_o(color_histogram.to_numpy(),proj_color_histogram[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('TW original', valor, 'Color_Histogram', tempo_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vF5Wnidi76FL"
      },
      "source": [
        "####Fibers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqv3Ouir704Z"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = trustworthiness_o(fibers.to_numpy(),proj_fibers[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('TW original', valor, 'Fibers', tempo_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x48ePqA8F1N"
      },
      "source": [
        "####Multifield"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aon8xir68JTG"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = trustworthiness_o(multifield.to_numpy(),proj_multifield[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('TW original', valor, 'Multifield', tempo_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Dldt4Ad8TEG"
      },
      "source": [
        "####Shuttle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uvo7BiIn8WZO"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = trustworthiness_o(shuttle.to_numpy(),proj_shuttle[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('TW original', valor, 'Shuttle', tempo_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vksTfiqK9AnV"
      },
      "source": [
        "####Phy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lSBtqqN9Cde"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = trustworthiness_o(phy.to_numpy(),proj_phy[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('TW original', valor, 'Phy', tempo_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIKdbJL_9QXw"
      },
      "source": [
        "###TW paralelizado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b221G1wc9pjv"
      },
      "source": [
        "####Mammals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZmO3-IbZi0W"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = trustworthiness_p(mammals.to_numpy(),proj_mammals[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('TW paralelizado', valor, 'mammals', tempo_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09gzSnwO92I4"
      },
      "source": [
        "####Color_Histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLAskc-k9z9v"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = trustworthiness_p(color_histogram.to_numpy(),proj_color_histogram[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('TW paralelizado', valor, 'Color_Histogram', tempo_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Z5zG1XB99IA"
      },
      "source": [
        "####Fibers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-slINPG97EG"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = trustworthiness_p(fibers.to_numpy(),proj_fibers[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('TW paralelizado', valor, 'Fibers', tempo_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P63s-QkX-C5m"
      },
      "source": [
        "####Multifield"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9N9hz7M-AeD"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = trustworthiness_p(multifield.to_numpy(),proj_multifield[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('TW paralelizado', valor, 'Multifield', tempo_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zf9wqpi8-IsH"
      },
      "source": [
        "####Shuttle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQblXhV8-GmO"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = trustworthiness_p(shuttle.to_numpy(),proj_shuttle[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('TW paralelizado', valor, 'Shuttle', tempo_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-cQxFjP-P6f"
      },
      "source": [
        "####Phy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYC-tCd5-Mne"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = trustworthiness_p(phy.to_numpy(),proj_phy[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('TW paralelizado', valor, 'Phy', tempo_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCPR2IFZ-VYi"
      },
      "source": [
        "##Teste CN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-jc423xIbtA"
      },
      "source": [
        "###CN original"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0WgWFWTIiFu"
      },
      "source": [
        "####Mammals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gJPy-ubIiFu"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = continuity(mammals.to_numpy(),proj_mammals[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('continuity original', valor, 'mammals', tempo_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90KqQfkMIiFv"
      },
      "source": [
        "####Color_Histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHFdCbECIiFw"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = continuity(color_histogram.to_numpy(),proj_color_histogram[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('continuity original', valor, 'Color_Histogram', tempo_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K45vdyQBIiFw"
      },
      "source": [
        "####Fibers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogh2X5K7IiFw"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = continuity(fibers.to_numpy(),proj_fibers[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('continuity original', valor, 'Fibers', tempo_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Pwlwpc2IiFw"
      },
      "source": [
        "####Multifield"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0sc0l2UIiFx"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = continuity(multifield.to_numpy(),proj_multifield[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('continuity original', valor, 'Multifield', tempo_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCVKxw3QIiFx"
      },
      "source": [
        "####Shuttle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46i45uGOIiFx"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = continuity(shuttle.to_numpy(),proj_shuttle[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('continuity original', valor, 'Shuttle', tempo_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLmdIDo6IiFy"
      },
      "source": [
        "####Phy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzsfE8oyIiFy"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = continuity(phy.to_numpy(),proj_phy[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('continuity original', valor, 'Phy', tempo_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHqdkQ6nHcDr"
      },
      "source": [
        "###CN paralelizado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvD-NDH2HVxb"
      },
      "source": [
        "####Mammals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6l4bXtoHVxb"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = continuity_p(mammals.to_numpy(),proj_mammals[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('continuity paralelizado', valor, 'mammals', tempo_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVbQxswDHVxd"
      },
      "source": [
        "####Color_Histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERE6xkMgHVxd"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = continuity_p(color_histogram.to_numpy(),proj_color_histogram[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('continuity paralelizado', valor, 'Color_Histogram', tempo_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNZ_87o4HVxe"
      },
      "source": [
        "####Fibers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mg9nCWyxHVxe"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = continuity_p(fibers.to_numpy(),proj_fibers[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('continuity paralelizado', valor, 'Fibers', tempo_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJInXZzVHVxf"
      },
      "source": [
        "####Multifield"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ke_y3CkpHVxf"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = continuity_p(multifield.to_numpy(),proj_multifield[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('continuity paralelizado', valor, 'Multifield', tempo_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3R4F9_N4HVxf"
      },
      "source": [
        "####Shuttle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-msVP7WHHVxg"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = continuity_p(shuttle.to_numpy(),proj_shuttle[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('continuity paralelizado', valor, 'Shuttle', tempo_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFSRE9ynHVxg"
      },
      "source": [
        "####Phy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfkQ_lOdHVxg"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = continuity_p(phy.to_numpy(),proj_phy[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('continuity paralelizado', valor, 'Phy', tempo_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKkNlGY3hEpi"
      },
      "source": [
        "##Teste Stress de Kruskal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QgiS6pLhTId"
      },
      "source": [
        "###Stress não paralelizado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQs82NQXhW8m"
      },
      "source": [
        "####mammals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qDpDyanhW8m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "bcdde48a-b677-4448-e424-9674bc3018f9"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = somatorio(mammals.to_numpy(),proj_mammals[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('Stress não paralelo', valor, 'mammals', tempo_final)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-e5be27cf81a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mtempo_inicio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mvalor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msomatorio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmammals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mproj_mammals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mtempo_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtempo_inicio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-eb9d21317008>\u001b[0m in \u001b[0;36msomatorio\u001b[0;34m(Matriz_o, Matriz_p)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMatriz_o\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# vai pegar a quantidade de linha e colunas respectivamente\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculation_parts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMatriz_o\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMatriz_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0msomab\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0msomat\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-eb9d21317008>\u001b[0m in \u001b[0;36mcalculation_parts\u001b[0;34m(Mo, Mp, stance, init, end, columns)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mdistanciaO\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstance\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# o mesmo caso anterior do commit anterior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mdistanciap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstance\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0msomab\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdistanciaO\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m  \u001b[0;31m# da formula onde a distancia do espaço projetado na parte inferior é elevado ao\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2241\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0;32m-> 2242\u001b[0;31m                           initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m                   if v is not np._NoValue}\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNrJzpnzhW8m"
      },
      "source": [
        "####Color Histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGwJVpMehW8n"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = somatorio(color_histogram.to_numpy(),proj_color_histogram[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('Stress não paralelo', valor, 'Color_Histogram', tempo_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKRRYfSshW8n"
      },
      "source": [
        "####Fibers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3rJM7XIhW8n"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = somatorio(fibers.to_numpy(),proj_fibers[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('Stress não paralelo', valor, 'Fibers', tempo_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VX2zJq9FhW8o"
      },
      "source": [
        "####Multifield"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIosLTWAhW8o"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = somatorio(multifield.to_numpy(),proj_multifield[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('Stress não paralelo', valor, 'Multifield', tempo_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8LaNDb9hW8o"
      },
      "source": [
        "####Shuttle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkUzy6CrhW8o"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = somatorio(shuttle.to_numpy(),proj_shuttle[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('Stress não paralelo', valor, 'Shuttle', tempo_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dttd1oQ7hW8p"
      },
      "source": [
        "####Phy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUZdJnbzhW8p"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = somatorio(phy.to_numpy(),proj_phy[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('Stress não paralelo', valor, 'Phy', tempo_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYFgS_oTsDjo"
      },
      "source": [
        "###Stress paralelizado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dciaVlmsDj2"
      },
      "source": [
        "####mammals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJYZ9lMBsDj3"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = somatorio_p(mammals.to_numpy(),proj_mammals[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('Stress paralelo', valor, 'mammals', tempo_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8cY2iGZsDj4"
      },
      "source": [
        "####Color Histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd4IX_5VsDj4"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = somatorio_p(color_histogram.to_numpy(),proj_color_histogram[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('Stress paralelo', valor, 'Color_Histogram', tempo_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7qVZ2EDsDj4"
      },
      "source": [
        "####Fibers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9E_7GpusDj5"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = somatorio_p(fibers.to_numpy(),proj_fibers[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('Stress paralelo', valor, 'Fibers', tempo_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXQ1hQX4sDj5"
      },
      "source": [
        "####Multifield"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lil-DmgesDj5"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = somatorio_p(multifield.to_numpy(),proj_multifield[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('Stress paralelo', valor, 'Multifield', tempo_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSdDe4XcsDj5"
      },
      "source": [
        "####Shuttle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWKmwDOAsDj6"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = somatorio_p(shuttle.to_numpy(),proj_shuttle[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('Stress paralelo', valor, 'Shuttle', tempo_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNm-Zcz6sDj6"
      },
      "source": [
        "####Phy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huYvsK0rsDj6"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  tempo_inicio = time.time()\n",
        "  valor = somatorio_p(phy.to_numpy(),proj_phy[i].to_numpy())\n",
        "  tempo_final = time.time() - tempo_inicio\n",
        "\n",
        "  salvar_arquivo('Stress paralelo', valor, 'Phy', tempo_final)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}